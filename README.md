[![Build Status](https://travis-ci.org/hussius/lstm_sandbox.svg?branch=master)](https://travis-ci.org/hussius/lstm_sandbox)

Working through seq2seq/encoder-decoder/attention tutorials starting from https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/

Run with `python train.py`.

Dependencies: numpy, keras, tensorflow